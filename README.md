# ðŸ¦™ LLaMA 3 Export (Tensor Parallel + ONNX)

This repository contains tools and scripts to export sharded LLaMA 3.2-1B model blocks to ONNX format using tensor parallelism via PyTorch Distributed.  
Supports model slicing, rank-wise export, and ZK-proof-ready computation blocks.

## ðŸš€ Features

- âœ… Shards LLaMA decoder blocks using tensor parallelism
- âœ… Supports rank-wise ONNX export (`layer0_rank{N}.onnx`)
- âœ… Output folder auto-managed and ignored from Git
- âœ… Modular architecture (TP, loaders, ONNX, CLI)
- âœ… Production-grade logging, CLI, and packaging

## ðŸ“¦ Usage

### Export layer 0 across GPUs:

```bash
torchrun --nproc_per_node=4 -m llama3_export.export